<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Kai S. Yun</title>
  
  <meta name="author" content="Kai Yun">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/ri_logo.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Kai S. Yun</name>
              </p>
              <p>I'm a MecEng Master's student in the <a href="http://icontrol.ri.cmu.edu/">Intelligent Control Lab (ICL)</a> and <a href="https://drive-lab-cmu.github.io/">Driverless Intelligent Vehicle Lab (DRIVE Lab)</a> at <a href="https://www.ri.cmu.edu/">Carnegie Mellon University Robotics Institute</a>. I am extremely fortunate to be advised by <a href="https://www.cs.cmu.edu/~cliu6/">Professor Changliu Liu</a> and <a href="https://www.ri.cmu.edu/ri-faculty/john-m-dolan/">Professor John Dolan</a>. 
              </p>
              <p>
              I work on safe control theory and performant robot learning, with humanoid, quadruped, and drone applications. My goal is to create safe and efficient autonomous systems that can operate in complex and dynamic environments.</p>
              </p>
              <p>
                Prior to CMU, I earned my B.S. (2023) from UC Berkeley with a major in <a href="https://me.berkeley.edu/">Mechanical Engineering</a> and a minor in <a href="https://eecs.berkeley.edu/">EECS</a>. During my time at Berkeley, I did safe reinforcement learning research under <a href="https://hybrid-robotics.berkeley.edu/koushil/">Professor Koushil Sreenath</a> in the <a href="https://hybrid-robotics.berkeley.edu/">Hybrid Robotics Group</a>. 
              </p>
              <p>
                Outside of school, I do kendo, scuba diving, and rock climbing.
              </p>
              <p style="text-align:center">
                <a href="mailto:sirkhooy@andrew.cmu.edu">Email</a> &nbsp;/&nbsp;
                <a href="data/CV_KaiYun.pdf">CV</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=kKpSxrIAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://github.com/kaiyun717">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/kai.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/kai.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News and Updates</heading>
              <p>In reverse chronological order:</p>
              <div class="news-container">
                <ul>
                  <li>
                      <strong>Jan. 2025:</strong> SPARK paper submitted to RSS!
                  <li>
                      <strong>Jan. 2025:</strong> Safe control for quadrupeds paper accepted to ICRA, see you in Atlanta!
                  <li>
                      <strong>Dec. 2024:</strong> Our new safe humanoid toolbox, SPARK, is out!
                  <li>
                      <strong>Nov. 2024:</strong> Demo'ed F1Tenth vehicles at <a href="https://safety21.cmu.edu/2024-deployment-partner-consortium-symposium/">Safety21 University Transportation Center</a>!
                  <li>
                      <strong>Oct. 2024:</strong> Started working on humanoids!
                  <li>
                      <strong>Sep. 2024:</strong> Safe navigation for package-carrying quadruped paper submitted to ICRA!
                  <li>
                      <strong>Jul. 2024:</strong> See you at ACC in Toronto!
                  <li>
                      <strong>Jun. 2024:</strong> Presented one paper at ECC in Stockholm!
                  <li>
                      <strong>Feb. 2024:</strong> Robust-adaptive controller paper accepted to ECC, see you in Sweden!
                  <li>
                      <strong>Jan. 2024:</strong> ModelVerification.jl paper submitted to CAV!
                  <li>
                      <strong>Oct. 2023:</strong> Robust-adaptive controller paper submitted to ECC!
                  <li>
                      <strong>Aug. 2023:</strong> I started my master's at CMU Mechanical Engineering!
                  <li>
                      <strong>Jul. 2023:</strong> I joined the Intelligent Control Lab @ CMU RI!
                  <li>
                      <strong>May. 2023:</strong> Graduated from UC Berkeley! See you in Pittsburgh!
                  <li>
                      <strong>May. 2023:</strong> Finished the EKF project for the Indy Autonomous Challenge!
                  <li>
                      <strong>May. 2022:</strong> I am joining Tesla as a Vehicle Dynamics / Software Engineering Intern!
                  <li>
                      <strong>Jul. 2021:</strong> I finished my 10-month internship as an RL Engineer at NeuroCore.ai!
                  <li> 
                      <strong>Jan. 2021:</strong> Back to Berkeley after my military service in the Korean Army!
                </ul>
              </div>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <!-- <p>
              My current research focuses on safety-critical control of autonomous systems. 
              </p> -->
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img style="width:105%;max-width:105%" src="images/SPARK.gif">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>SPARK: A Modular Benchmark for Humanoid Robot Safety</papertitle>
              <br>
              Yifan Sun, 
              Rui Chen, 
              <strong>Kai S. Yun</strong>,
              Yikuan Fang, 
              Sebin Jung, 
              Feihan Li, 
              Bowei Li, 
              Weiye Zhao, 
              Changliu Liu
              <br>
              <em>Submitted to Robotics: Science and Systems (RSS), 2025.</em> 
              <br>
              <a href="https://intelligent-control-lab.github.io/spark/">Website</a> | <a href="https://arxiv.org/abs/2502.03132">ArXiv</a> | <a href="https://www.youtube.com/watch?v=vIzeQ31YbCM">Video</a>
              <br>
              <p></p>
              <p> 
                To alleviate the challenge of robust safety measures in general humanoid operation, we introduce the Safe Protective and Assistive Robot Kit (SPARK), a modular toolbox that integrates state-of-the-art safe control algorithms into a generic humanoid control framework. 
                SPARK enables users to configure safety behaviors across multiple dimensions, such as defining safety criteria and sensitivity levels, allowing for optimized trade-offs between safety and performance. 
              </p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img style="width:105%;max-width:105%" src="images/ICRA-sia_go2.gif">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Safe Control of Quadruped in Varying Dynamics via Safety Index Adaptation</papertitle>
              <br>
              <strong>Kai S. Yun</strong>,
              Rui Chen,
              Chase Dunaway,
              John M. Dolan,
              Changliu Liu
              <br>
              <em>Accepted to International Conference on Robotics and Automation (ICRA), 2025.</em>
              <br>
              <a href="https://www.arxiv.org/abs/2409.09882">ArXiv</a> | <a href="https://youtu.be/3TrRPJcUo-k">Video</a>
              <br>
              <p></p>
              <p> 
                We deploy Safety Index Adaptation (SIA) for a quadruped robot to safely navigate in varying dynamics. SIA enables real-time adaptation of safety indices to ensure provable safety. 
                With SIA, the quadruped carries packages of varying weights and sizes while navigating through obstacles without failure. Moreover, we introduce a novel linear model for varying quadruped dynamics and a method to identify the changing dynamics. 
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img style="width:105%;max-width:105%" src="images/ECC-CartPole.gif">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Synthesis and Verification of Robust-Adaptive Safe Controllers</papertitle>
              <br>
              Simin Liu*, 
              <strong>Kai S. Yun</strong>*,
              John M. Dolan,
              Changliu Liu
              <br>
              <em>Published in European Control Conference (ECC), 2024.</em>
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/10590909">IEEE</a> | <a href="https://arxiv.org/abs/2311.00822">ArXiv</a>
              <br>
              <p></p>
              <p> 
                We investigate controller synthesis for dynamical systems with uncertain parameters. We designed an optimization algorithm for generating robust-adaptive safe controllers 
                that can guarantee safety in the presence of uncertainties, without being overly conservative. Our controller performs 55% better compared to popular robust controllers.  
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img style="width:105%;max-width:105%" src="images/mvjl.png">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>ModelVerification.jl: a Comprehensive Toolbox for Formally Verifying Deep Neural Networks</papertitle>
              <br>
              Tianhao Wei, 
              Luca Marzari*, 
              <strong>Kai S. Yun</strong>*, 
              Hanjiang Hu*, 
              Peizhi Niu*, 
              Xusheng Luo, 
              Changliu Liu
              <br>
              <em>Under review at International Conference on Computer Aided Verification (CAV), 2024.</em>
              <br>
              <a href="https://arxiv.org/abs/2407.01639v1">ArXiv</a> | <a href="https://github.com/intelligent-control-lab/ModelVerification.jl">GitHub</a>
              <!-- <br> -->
              <p></p>
              <p> 
                We introduce a new comprehensive toolbox for formally verifying deep neural networks. ModelVerification.jl is a Julia package (with Python interface) that provides a wide range of 
                state-of-the-art verification algorithms for various deep neural networks. This toolbox is designed to be user-friendly and efficient, and it is open-source.  
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img style="width:105%;max-width:105%" src="images/dunham.png">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Mass-independent Dunham Analysis of the [7.7] Y2 Σ+ – X2 Πi and [16.3] A2 Σ− – X2 Πi Transitions of Copper Monoxide, CuO</papertitle>
              <br>
              Jack C. Harms, 
              Ethan M. Grames, 
              <strong>SirkHoo Yun</strong>, 
              Bushra Ahmed, 
              Leah C. O'Brien, 
              James J. O'Brien
              <br>
              <em>Journal of Molecular Spectroscopy, 2019.</em>
              <br>
              <a href="https://www.sciencedirect.com/science/article/pii/S0022285219300785">Journal of Molecular Spectroscopy</a>
              <br>
              <p></p>
              <p> 
                The previous literature on the electronic spectrum of Copper-63 Oxide is extended to Copper-65 Oxide. We combine the analysis of A-X and Y-X electronic 
                systems of Copper-65 Oxide, using the mass-independent Dunham fit with PGOPHER software to obtain molecular constants. Moreover, Copper-isotope field-shift is corrected to 
                the electronic exictation energy required in the fit of Y-X system.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Projects</heading>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img style="width:105%;max-width:105%" src="images/teleoperation.gif">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle>Humanoid Teleoperation</papertitle>
            <br>
            <a href="https://youtu.be/PpGsAPw_rFo">Demo video</a>
            <br>
            <p></p>
            <p> 
              In this project, we developed a teleoperation system for Unitree G1 humanoid robot with Apple Vision Pro (AVP). 
              Using the AVP, the system tracks the human operator's hands and translates the end-effector poses into the humanoid's upper-body movements.
            </p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img style="width:105%;max-width:105%" src="images/lqr-quadrotor.gif">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle>Balancing an inverted pendulum on quadrotor with LQR</papertitle>
            <br>
            <a href="https://www.youtube.com/watch?v=xv5zaImMktg&feature=youtu.be">Demo video</a>
            <br>
            <p></p>
            <p> 
              For this project, we implemented a Linear Quadratic Regulator (LQR) controller to balance an inverted pendulum on a quadrotor. 
              I built the quadrotor, named "Danaus-12", with PX4-Autopilot firmware. A carbon fiber tube is used as the pendulum and it is not mechanically 
              attached to the quadrotor. Instead, it simply rests on the quadrotor and the LQR controller is used to balance the pendulum. 
              The quadrotor is controlled with an offboard computer and I used a Vicon motion capture system to track the positions of the quadrotor and pendulum.  
              This work is based on <a href="https://ieeexplore.ieee.org/document/5980244">"A flying inverted pendulum"</a>, by Markus Hehn and Raffaello D'Andrea from ETH.
            </p>
          </td>
        </tr>
      </tbody></table>

      <!-- Start of Image Row -->
       <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Hardwares</heading>
            </td>
          </tr>
        </tbody></table>
  
      <table style="width:100%; border:0; border-spacing:0; border-collapse:separate; margin:auto;">
        <tbody>
          <tr>
            <td style="padding:20px; width:25%; vertical-align:bottom; text-align:center;">
              <img src="images/g1.jpg" alt="G1" style="width:100%; max-width:100%;">
              <br>
              <small><a href="https://youtu.be/PpGsAPw_rFo">Unitree G1</a></small>
            </td>
            <td style="padding:20px; width:25%; vertical-align:bottom; text-align:center;">
              <img src="images/go2_package.png" alt="Go2" style="width:100%; max-width:100%;">
              <br>
              <small><a href="https://youtu.be/3TrRPJcUo-k">Unitree Go2</a></small>
            </td>
            <td style="padding:20px; width:25%; vertical-align:bottom; text-align:center;">
              <img src="images/danaus12.png" alt="Drone" style="width:100%; max-width:100%;">
              <br>
              <small><a href="https://youtu.be/xv5zaImMktg">PX4 Quadrotor</a></small>
            </td>
            <td style="padding:20px; width:25%; vertical-align:bottom; text-align:center;">
              <img src="images/f1tenth.jpg" alt="RC" style="width:100%; max-width:100%;">
              <br>
              <small><a href="https://youtu.be/Q2sEgWqN7uE">F1Tenth</a></small>
            </td>
          </tr>
        </tbody>
      </table>
      <!-- End of Image Row -->
  
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Experiences</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px 20px 20px 20px;width:75%;vertical-align:middle">
              <a href="https://www.tesla.com/"> Tesla, Inc.</a>, <b>Vehicle Dynamics Team</b>
              <br>
              Vehicle Dynamics / Software Engineering Intern • May 2022 to August 2022
              </br>
            </td>
            <td style="padding:0px 20px 0px 20px;width:10%;vertical-align:middle"><img src="images/Tesla_logo.png" width="75" height="75"></td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px 20px 20px 20px;width:75%;vertical-align:middle">
              <a href="https://www.neurocore.ai/"> NeuroCore.ai.</a>, <b>Reinforcement Learning Team</b>
              <br>
              Reinforcement Learning Research Intern • October 2020 to July 2021
              </br>
            </td>
            <td style="padding:0px 20px 0px 20px;width:10%;vertical-align:middle"><img src="images/neurocore_logo.png" width="75" height="75"></td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://github.com/jonbarron/jonbarron_website">Website template from Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>

      </td>
    </tr>
  </table>
</body>


</html>
